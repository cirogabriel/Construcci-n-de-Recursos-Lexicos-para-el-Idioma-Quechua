{"cells":[{"cell_type":"markdown","metadata":{"id":"F1sg2NL5ZHJo"},"source":["# **PROCESAMIENTO DE LENGUAJE NATURAL**\n","\n","## **NLTK**\n","\n","NLTK (Natural Language Toolkit) es una biblioteca de procesamiento de lenguaje natural (PLN) de código abierto y uno de los recursos más utilizados en Python para tareas de PLN. Proporciona una amplia gama de herramientas y recursos para trabajar con texto en lenguaje natural, incluyendo tokenización, análisis sintáctico, etiquetado de partes del discurso, análisis de sentimientos, y mucho más. NLTK también ofrece acceso a una variedad de corpus y recursos lingüísticos, lo que lo convierte en una opción popular para la investigación académica y el desarrollo de aplicaciones en PLN. Su diseño modular y su amplia comunidad de usuarios y desarrolladores lo hacen adecuado tanto para principiantes como para usuarios avanzados que desean realizar tareas sofisticadas de procesamiento de lenguaje natural en Python.\n","\n","Sitio oficial: https://www.nltk.org/\n","\n"]},{"cell_type":"markdown","source":["## **Conceptos sobre Procesmiento de Lenguaje Natural**"],"metadata":{"id":"-La5KwBbg4QH"}},{"cell_type":"markdown","source":["### **1. Corpus:**\n","\n","En el procesamiento del lenguaje natural (NLP), un corpus, que deriva del término latino \"cuerpo\", se refiere a una recopilación o colección de textos que pueden abarcar una amplia variedad de fuentes, como artículos periodísticos, libros, críticas, mensajes en redes sociales como tweets, entre otros. Es esencialmente un conjunto de datos textuales que se utiliza para entrenar modelos de NLP, realizar investigaciones lingüísticas o realizar análisis de texto en diversos campos"],"metadata":{"id":"FdF6b1W9hhiG"}},{"cell_type":"markdown","source":["### **2. Bag of Words (BoW):**\n","\n","***BoW*** (Bolsa de palabras) es un modelo que se utiliza para simplificar el contenido de un documento (o conjunto de documentos) omitiendo la gramática y el orden de las palabras, centrándose solo en el número de ocurrencias de palabras dentro del texto.\n","\n","**Tipos de representaciones de \"bag of words\"**\n","\n","Hay varios tipos de representaciones de \"bag of words\" que se utilizan en el procesamiento de lenguaje natural. Aquí hay algunos ejemplos:\n","\n","- **Binary Bag of Words (BBOW):** Esta representación simplemente indica si una palabra está presente o no en el texto, ignorando la frecuencia de ocurrencia.\n","\n","- **Term Frequency (TF):** Aquí, se registra la frecuencia de cada palabra en el texto. Es decir, cuántas veces aparece cada palabra.\n","\n","- **Term Frequency-Inverse Document Frequency (TF-IDF):** Esta técnica ajusta las frecuencias de términos (TF) al considerar la frecuencia de cada palabra en el contexto de todos los documentos disponibles (el corpus). Esto reduce la importancia de las palabras comunes y resalta las palabras más relevantes para un documento específico.\n","\n","- **N-gram Bag of Words:** En lugar de considerar palabras individuales, se consideran secuencias contiguas de palabras de longitud n (n-gramas). Por ejemplo, para n=2, se consideran pares de palabras consecutivas.\n","\n","- **Character-based Bag of Words:** En este enfoque, las unidades básicas no son palabras sino caracteres. Cada caracter se trata como una \"palabra\" individual.\n","\n","- **Skip-gram Bag of Words:** Similar a los n-gramas, pero permite saltar cierto número de palabras entre cada palabra incluida en la representación. Esto puede ayudar a capturar relaciones semánticas más complejas.\n"],"metadata":{"id":"12_kV_anhoux"}},{"cell_type":"markdown","source":["### **3. Normalización:**\n","\n","La ***normalización*** es una tarea que tiene como objetivo poner todo el texto en igualdad de condiciones, mediante las siguientes acciones:\n","\n","* Convertir todo el texto en mayúscula o minúsculas\n","* Eliminar, puntos, comas, comillas, etc.\n","* Convertir los números a su equivalente a palabras\n","* Quitar palabras que no aportan significado al texto (Stop-words)\n","* Etc."],"metadata":{"id":"Wxqxi7Ybhr_P"}},{"cell_type":"markdown","source":["### **4. Tokenización:**\n","\n","Es una tarea que divide las cadenas de texto del documento en piezas más pequeñas o tokens. En la fase de tokenización los documentos se dividen en oraciones y estas se \"tokenizan\" en palabras. Aunque la tokenización es el proceso de dividir grandes cadenas de texto en cadenas más pequeñas, se suele diferenciar la:\n","\n","* ***Segmentación***: Tarea de dividir grandes cadenas de texto en piezas más pequeñas como oraciones o párrafos.\n","\n","* **Tokenización***: Tarea de dividir grandes cadenas de texto solo y exclusivamente en palabras."],"metadata":{"id":"qhrgtLoLh3aK"}},{"cell_type":"markdown","source":["### **5. Stemming:**\n","\n","***Stemming*** es el proceso de eliminar los afijos (sufijos, prefijos, infijos, circunfijos) de una palabra para obtener la raiz de las palabras.\n","\n","*Ejemplo*: Conduciendo -> conducir"],"metadata":{"id":"2DPvFjmNh641"}},{"cell_type":"markdown","source":["### **6. Lematización:**\n","\n","\n","* La ***lematización*** es el proceso lingüístico que sustituye una palabra con forma flexionada (plurales, femeninos, verbos conjugados, etc.) por su lema; es decir, por una palabra válida en el idioma.\n","\n","\n","* Si lo queremos definir de otra manera es sustituir una palabra con forma flexionada por la palabra que encontraríamos en el diccionario.\n","\n","    + *Ejemplo*: Coches -> Coche; Guapas -> Guapo"],"metadata":{"id":"hVP9HEmDh_cp"}},{"cell_type":"markdown","source":["### **7. Stop Words:**\n","\n","Son palabras que no aportan nada al significado de las frases como las preposiciones, determinantes, etc."],"metadata":{"id":"m0HrGLPMiEc6"}},{"cell_type":"markdown","source":["### **8. Parts-of-speech (POS) Tagging:**\n","\n","* Consiste en asignar una etiqueta de categoría a las partes tokenizadas de una oración. El etiquetado POS más popular sería identificar palabras como sustantivos, verbos, adjetivos, etc.\n","\n","* En la lengua castellana podemos encontrar 9 categorías de palabras:\n","\n","    - Artículo o determinante\n","    - Sustantivo o nombre\n","    - Pronombre\n","    - Verbo\n","    - Adjetivo\n","    - Adverbio\n","    - Preposición\n","    - Conjunción\n","    - Interjección"],"metadata":{"id":"vAJHrmHLiKWN"}},{"cell_type":"markdown","source":["### **9. n-gramas:**\n","\n","* Los ***n-gramas*** son otro modelo de representación para simplificar los contenidos de selección de texto.\n","\n","* A diferencia de la representación sin orden de una bolsa de palabras (bag of words), el modelado de n-gramas está interesado en preservar secuencias contiguas de N elementos de la selección de texto.\n","* Por ejemplo, la oración \"Me gusta el pastel de manzana\" se puede modelar como:\n","\n","> - Unigramas (1-gramas): \"Me\", \"gusta\", \"el\", \"pastel\", \"de\", \"manzana\". Cada palabra se considera individualmente.\n","> - Bigramas (2-gramas): \"Me gusta\", \"gusta el\", \"el pastel\", \"pastel de\", \"de manzana\". Cada par de palabras adyacentes se considera como una unidad.\n","> - Trigramas (3-gramas): \"Me gusta el\", \"gusta el pastel\", \"el pastel de\", \"pastel de manzana\". Cada trio de palabras adyacentes se considera como una unidad.\n","> - 4-gramas: \"Me gusta el pastel\", \"gusta el pastel de\", \"el pastel de  manzana\". Cada secuencia de cuatro palabras adyacentes se considera como una unidad.\n","\n","<hr>"],"metadata":{"id":"auL5cHEWgicQ"}},{"cell_type":"markdown","source":["## **Ejemplos con NLTK**"],"metadata":{"id":"ZqsYs02BLN1P"}},{"cell_type":"markdown","metadata":{"id":"_OxEcclGZHJy"},"source":["### **Tokenización**\n","\n","* Divide las cadenas de texto del documento en piezas más pequeñas o tokens."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Dti1zbxcZHJ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703404103,"user_tz":300,"elapsed":4489,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"e7ce5b61-63f1-4f9c-e715-5e9fb0578e34"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","nltk.download('punkt')\n","# Punkt is a tokenizer that divides text into a list of sentences using an unsupervised algorithm.\n","# https://www.nltk.org/_modules/nltk/tokenize/punkt.html\n","nltk.download('punkt_tab') # Download punkt_tab resource"]},{"cell_type":"code","source":["# ejemplo de tokenizacion\n","from nltk import word_tokenize\n","doc = \"Los libros constituyen una fuente de conocimiento inagotable\"\n","\n","# Tokenizar el texto. word_tokenize utiliza el tokenizador punkt\n","words = nltk.word_tokenize(doc)\n","print (words)"],"metadata":{"id":"kf3Rfx9EM7wu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703671916,"user_tz":300,"elapsed":45,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"f46de1de-c4c4-498e-8166-f905da09589a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['Los', 'libros', 'constituyen', 'una', 'fuente', 'de', 'conocimiento', 'inagotable']\n"]}]},{"cell_type":"markdown","metadata":{"id":"c3KvFxKfZHJ4"},"source":["### **Stemming con NLTK**\n","\n","* Para realizar el Stemming con NLTK tenemos que seleccionar el \"Stemmer\" adecuado dependiendo del idioma.\n","\n","\n","* En NLTK existen dos \"Stemmers\" que son los siguientes:\n","    * PorterStemmer\n","    * SnowballStemmer\n","\n","\n","* Para más información sobre estos ver el siguiente enlace: http://www.nltk.org/howto/stem.html\n","<span></span><br>\n","* *Ejemplo en Inglés* con el *PorterStemmer*"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0vwSSDc9ZHJ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703614669,"user_tz":300,"elapsed":70,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"e01971b2-d56d-49cd-cc3d-2dbb913a7e7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["run\n","read\n","read\n","minimum\n"]}],"source":["# importamos el stemmer PorterStemmer\n","from nltk.stem import PorterStemmer\n","stm = PorterStemmer()\n","\n","print (stm.stem('running'))\n","print(stm.stem('readed'))\n","print(stm.stem('reading'))\n","print (stm.stem('minimum'))"]},{"cell_type":"code","source":["# Texto de ejemplo en español\n","texto = \"Correrá corriendo corrió.\"\n","\n","# Tokenizar el texto en palabras\n","palabras = word_tokenize(texto)\n","\n","# Aplicar stemming a cada palabra en el texto\n","stemmed_words = [stm.stem(palabra) for palabra in palabras]\n","\n","# Imprimir las palabras originales y sus formas stem\n","for palabra, stemmed_word in zip(palabras, stemmed_words):\n","  print(f\"Palabra original: {palabra}, Forma stem: {stemmed_word}\")"],"metadata":{"id":"2SkH9PQP_As1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703674279,"user_tz":300,"elapsed":8,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"9c1f65ae-dd5a-41b0-f8e3-1f5247bc1c00"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra original: Correrá, Forma stem: correrá\n","Palabra original: corriendo, Forma stem: corriendo\n","Palabra original: corrió, Forma stem: corrió\n","Palabra original: ., Forma stem: .\n"]}]},{"cell_type":"markdown","metadata":{"id":"4cpIKs9RZHJ5"},"source":["Los Stemmers de NLTK para idiomas distintos al inglés son relativamente malos ya que NLTK esta pensado para la lengua inglesa.\n","* **Ejemplo en Español** con el *SnowballStemmer*"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EOkyHnA1ZHJ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703713293,"user_tz":300,"elapsed":33,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"97c9b18d-97fe-4802-d1cb-99e9a5b0a34e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra original: corriendo, Palabra derivada: corr\n","Palabra original: correría, Palabra derivada: corr\n","Palabra original: corrió, Palabra derivada: corr\n","Palabra original: corriendo, Palabra derivada: corr\n","Palabra original: correr, Palabra derivada: corr\n","Palabra original: corre, Palabra derivada: corr\n","Palabra original: corres, Palabra derivada: corr\n"]}],"source":["# importamos el stemmer SnowballStemmer\n","from nltk.stem import SnowballStemmer\n","\n","# creamos un nuevo objeto SnowballStemmer para el idioma español\n","stm = SnowballStemmer('spanish')\n","\n","# Ejemplo de palabras a derivar\n","palabras = [\"corriendo\", \"correría\", \"corrió\", \"corriendo\", \"correr\", \"corre\", \"corres\"]\n","\n","# Derivación de palabras\n","for palabra in palabras:\n","  print(f\"Palabra original: {palabra}, Palabra derivada: {stm.stem(palabra)}\")"]},{"cell_type":"code","source":["# Ejemplo de palabras a derivar\n","palabras = [\"gato\", \"gatos\", \"gata\", \"gatas\", \"gatito\", \"gatitos\", \"gatita\", \"gatitas\"]\n","\n","# Derivación de palabras\n","for palabra in palabras:\n","  print(f\"Palabra original: {palabra}, Palabra derivada: {stm.stem(palabra)}\")"],"metadata":{"id":"OiVa3tsfu-pb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703717494,"user_tz":300,"elapsed":7,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"7f1edd2a-5220-4ad6-b996-9d43a264c3a5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra original: gato, Palabra derivada: gat\n","Palabra original: gatos, Palabra derivada: gat\n","Palabra original: gata, Palabra derivada: gat\n","Palabra original: gatas, Palabra derivada: gat\n","Palabra original: gatito, Palabra derivada: gatit\n","Palabra original: gatitos, Palabra derivada: gatit\n","Palabra original: gatita, Palabra derivada: gatit\n","Palabra original: gatitas, Palabra derivada: gatit\n"]}]},{"cell_type":"markdown","metadata":{"id":"CHCC9t1eZHKA"},"source":["### **Lematización**\n","\n","NLTK ofrece funcionalidades de lematización para varios idiomas, aunque su desempeño puede ser mejor en inglés debido a la disponibilidad de recursos lingüísticos y modelos específicos para ese idioma. La lematización en NLTK se basa en reglas y recursos léxicos, lo que puede limitar su precisión en idiomas con estructuras lingüísticas más complejas o menos recursos disponibles.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"P_PGJKVsZHKA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703838252,"user_tz":300,"elapsed":291,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"8598f16a-8b91-4493-b312-c0ac9ea3543b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}],"source":["# Descarga de WordNet para la lematización en inglés\n","nltk.download('wordnet')  # WordNet es una base de datos léxica de inglés que se utiliza para la lematización en NLTK.\n","\n","# Descarga de Open Multilingual WordNet (OMW) para la lematización en varios idiomas\n","nltk.download('omw-1.4')  # Open Multilingual WordNet (OMW) es una extensión de WordNet que proporciona recursos léxicos en varios idiomas para la lematización en NLTK.\n"]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","# Inicializar el lematizador WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# Definir una lista de palabras en inglés para lematizar\n","palabras_ingles = [\"dogs\", \"running\", \"rocks\", \"geese\", \"churches\"]\n","\n","# Lematizar las palabras en inglés\n","for palabra in palabras_ingles:\n","  lema = lemmatizer.lemmatize(palabra)\n","  print(f\"Palabra original: {palabra}, Lema: {lema}\")"],"metadata":{"id":"rrYnjOvYNlyM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703859226,"user_tz":300,"elapsed":3414,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"aa35105c-71b5-47d2-c941-22b9133b44eb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra original: dogs, Lema: dog\n","Palabra original: running, Lema: running\n","Palabra original: rocks, Lema: rock\n","Palabra original: geese, Lema: goose\n","Palabra original: churches, Lema: church\n"]}]},{"cell_type":"code","source":["# Definir una lista de palabras en español para lematizar\n","palabras_espanol = [\"corriendo\", \"correría\", \"corrió\", \"corredor\", \"corredores\"]\n","\n","# Lematizar las palabras en español\n","for palabra in palabras_espanol:\n","  lema = lemmatizer.lemmatize(palabra, pos='v')\n","  print(f\"Palabra original: {palabra}, Lema: {lema}\")"],"metadata":{"id":"i_0lfDuPxbxk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756302457371,"user_tz":300,"elapsed":60,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"e1fe8c20-aedd-45da-bbb2-9d709024813e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Palabra original: corriendo, Lema: corriendo\n","Palabra original: correría, Lema: correría\n","Palabra original: corrió, Lema: corrió\n","Palabra original: corredor, Lema: corredor\n","Palabra original: corredores, Lema: corredores\n"]}]},{"cell_type":"markdown","metadata":{"id":"0k42sJS5ZHKB"},"source":["### **Stop words**\n","\n","* NLTK proporciona una lista de 'Stop Words' para varios idiomas.\n","\n","\n","* Para el Español dispone de un listado de stop words:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"rPKCeDpxZHKC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703906685,"user_tz":300,"elapsed":48,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"b30bcbb4-d0ab-4ad4-d4ef-f0ddd8dccb8d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}],"source":["# descargar las stopwords\n","nltk.download('stopwords')"]},{"cell_type":"code","source":["# importamos el módulo stopwords del paquete nltk.corpus\n","from nltk.corpus import stopwords\n","\n","# mostramos las stopwords en español\n","print(set(stopwords.words('spanish')))\n"],"metadata":{"id":"40D5JMlqNuAo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756703939584,"user_tz":300,"elapsed":96,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"a0b495fd-6d38-456d-e8f6-9da6802f55d7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["{'habías', 'estuviésemos', 'sentidas', 'estuviéramos', 'sobre', 'para', 'muchos', 'tendrán', 'hayáis', 'estés', 'seríamos', 'algunas', 'estará', 'teníais', 'estar', 'tenido', 'estarán', 'por', 'seremos', 'estuvierais', 'estaría', 'habrían', 'otra', 'has', 'les', 'tanto', 'seréis', 'tendrás', 'su', 'vosotros', 'estás', 'eso', 'haya', 'otros', 'nosotras', 'e', 'tengáis', 'estuvieseis', 'mucho', 'hayan', 'estaremos', 'seríais', 'había', 'ante', 'antes', 'fueron', 'el', 'hubieran', 'estaré', 'tenían', 'seré', 'en', 'todo', 'estuviesen', 'habíais', 'estuvieras', 'soy', 'tuyas', 'con', 'habré', 'vuestros', 'esto', 'algunos', 'tendremos', 'será', 'mí', 'pero', 'erais', 'habréis', 'habidas', 'habremos', 'fuésemos', 'hube', 'estemos', 'tiene', 'tenidas', 'contra', 'hubieron', 'esa', 'sois', 'durante', 'estuvieses', 'donde', 'estuvisteis', 'al', 'fuisteis', 'no', 'tuvieseis', 'habría', 'tuviesen', 'estuviste', 'mis', 'tuviésemos', 'fuerais', 'está', 'ni', 'hay', 'que', 'poco', 'estáis', 'estaban', 'hubierais', 'las', 'ellas', 'suya', 'tuvisteis', 'nuestros', 'una', 'tuvieras', 'ha', 'te', 'tengas', 'seamos', 'estaríais', 'le', 'hemos', 'habido', 'seáis', 'estuve', 'tendrá', 'estados', 'hasta', 'hubisteis', 'tuviese', 'fueras', 'sentida', 'habrás', 'ya', 'fueseis', 'fueran', 'tuvo', 'ella', 'estábamos', 'tenidos', 'fuéramos', 'tenéis', 'y', 'fui', 'fuiste', 'cuando', 'estamos', 'tuviera', 'hubiésemos', 'tuyos', 'del', 'algo', 'habíamos', 'nuestra', 'este', 'yo', 'tengo', 'nos', 'están', 'estaréis', 'estabais', 'tuviste', 'hubo', 'estuvimos', 'todos', 'tuvieran', 'tendréis', 'estadas', 'nuestro', 'qué', 'estarían', 'él', 'estaba', 'habidos', 'eras', 'tengamos', 'serán', 'habéis', 'tienen', 'mío', 'sentid', 'cual', 'hubieras', 'estabas', 'suyo', 'fuera', 'habían', 'unos', 'fuesen', 'son', 'como', 'tuve', 'sin', 'siente', 'porque', 'sus', 'mi', 'vosotras', 'habríamos', 'ti', 'tus', 'seas', 'hubiéramos', 'serás', 'entre', 'habrá', 'un', 'habrán', 'serían', 'han', 'teniendo', 'éramos', 'vuestro', 'teníamos', 'sea', 'sí', 'de', 'somos', 'suyos', 'más', 'fuimos', 'tendría', 'tened', 'habríais', 'o', 'esta', 'estad', 'habiendo', 'he', 'os', 'nosotros', 'otras', 'tuvierais', 'sean', 'fue', 'vuestras', 'tendrías', 'me', 'estas', 'estuvieron', 'tuvieses', 'estaríamos', 'tengan', 'estuvieran', 'sería', 'tú', 'estos', 'tuvimos', 'vuestra', 'hubiera', 'tendré', 'estoy', 'quienes', 'a', 'hubieses', 'mía', 'hubiste', 'también', 'tienes', 'quien', 'era', 'estuviera', 'tuya', 'tendríais', 'ellos', 'tuvieron', 'esas', 'esté', 'estado', 'tenía', 'muy', 'fuese', 'nuestras', 'tuyo', 'mías', 'serías', 'estén', 'ese', 'hayas', 'míos', 'desde', 'fueses', 'estuviese', 'tenemos', 'lo', 'hayamos', 'habida', 'esos', 'hubiese', 'la', 'tenías', 'eres', 'los', 'uno', 'sintiendo', 'sentidos', 'estada', 'tu', 'sentido', 'otro', 'estando', 'habrías', 'suyas', 'es', 'tenida', 'estarás', 'hubieseis', 'eran', 'tendrían', 'tendríamos', 'se', 'estarías', 'hubimos', 'tenga', 'estéis', 'tuviéramos', 'estuvo', 'hubiesen', 'nada'}\n"]}]},{"cell_type":"markdown","metadata":{"id":"1Ntrp8GTZHKE"},"source":["* Este listado de palabras se utiliza para eliminarlas de los textos.\n","\n","\n","* Veamos a continuación como obtener las stop words de una frase tras su tokenización."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"w8T7O7VZZHKG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756704121466,"user_tz":300,"elapsed":18,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"205358f2-de2b-40fa-fd18-618f95d8ef94"},"outputs":[{"output_type":"stream","name":"stdout","text":["una\n","de\n"]}],"source":["# Texto de ejemplo\n","doc = \"Los libros constituyen una fuente de conocimiento inagotable\"\n","\n","# Tokenizar el texto en palabras\n","words = nltk.word_tokenize(doc)\n","\n","# Iterar sobre cada palabra en el texto\n","for word in words:\n","  if word in stopwords.words('spanish'):\n","    print(word)\n"]},{"cell_type":"code","source":["# Texto de ejemplo\n","doc2 = \"El viaje es una aventura que nos permite descubrir nuevas culturas y paisajes increíbles.\"\n","\n","# Tokenizar el texto en palabras\n","words = nltk.word_tokenize(doc2)\n","\n","# Iterar sobre cada palabra en el texto\n","for word in words:\n","  if word in stopwords.words('spanish'):\n","    print(word)\n"],"metadata":{"id":"9Z7NrG_bykgR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756704212402,"user_tz":300,"elapsed":9,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"e161fb29-ae1c-4afa-8e3d-d5ea6c624cc1"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["es\n","una\n","que\n","nos\n","y\n"]}]},{"cell_type":"markdown","metadata":{"id":"Znem0m7GZHKH"},"source":["### **Part-of-Speech Tagging - Etiquetado gramatical**\n","\n","* El PoS Tagging de NLTK sólo está disponible para el inglés. Algunas de sus categorías gramaticales son:\n","\n","<CENTER>\n","\n","|Tag|Meaning|\n","|---|---|\n","|ADJ|adjective|\n","|ADP|adposition|\n","|ADV|adverb|\n","|CONJ|conjunction|\n","|DET|determiner|\n","|NOUN|noun|\n","|NUM|numeral|\n","|PRT|particle|\n","|PRON|pronoun|\n","|VERB|verb|\n","|.|punctuation|\n","|X|other|\n","\n","</CENTER>\n","\n","\n","* Nota: La tabla anterior no significa que solo asigne esas categorias, si no que tiene esas categorias y luego las va desgranando; por ejemplo, los verbos o adjetivos pueden ser de diferentes tipos y les pondrá una etiqueta en función de ese tipo. [Tag Words](https://www.nltk.org/book/ch05.html)\n","\n","* Sitio recomendado: https://cheatography.com/deacondesperado/cheat-sheets/nltk-part-of-speech-tags/\n","\n","* Veamos a continuación un ejemplo:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wouJAXB1ZHKJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756704395442,"user_tz":300,"elapsed":283,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"63894599-36e3-4139-e5c4-0b41e0bd4646"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"stream","name":"stdout","text":["[('Is', 'VBZ'), ('marathon', 'JJ'), ('running', 'VBG'), ('bad', 'JJ'), ('for', 'IN'), ('you', 'PRP'), ('?', '.')]\n"]}],"source":["# Descargar recursos necesarios para el etiquetado de partes del discurso (POS)\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('averaged_perceptron_tagger_eng')\n","\n","\n","# Texto de ejemplo\n","doc = nltk.word_tokenize('Is marathon running bad for you?')\n","\n","# Etiquetado de partes del discurso (POS)\n","pos_tags = nltk.pos_tag(doc)\n","\n","# Imprimir los POS tags de cada palabra en el texto\n","print(pos_tags)"]},{"cell_type":"code","source":["# Texto de ejemplo\n","doc2 = \"The quick brown fox jumps over the lazy dog.\"\n","\n","# Tokenizar el texto en palabras\n","words = nltk.word_tokenize(doc2)\n","\n","# Etiquetado de partes del discurso (POS)\n","pos_tags = nltk.pos_tag(words)\n","\n","# Imprimir los POS tags de cada palabra en el texto\n","print(pos_tags)"],"metadata":{"id":"muQSbgPjzViP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756704435385,"user_tz":300,"elapsed":19,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"22d8b790-adae-42b6-8bad-7b7bf3d45ae6"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-ks16ypNZHKK"},"source":["### **PoS Tagging en Español:**\n","\n","\n","* Para poder etiquetar correctamente las palabras en español, tenemos que descargar un diccionario específico para esta lengua.\n","\n","\n","* El grupo de Procesamiento de Lenguaje Natural de la Universidad de Stanford ha desarrollado un diccionario en castellano que nos permite etiquetar las palabras. En el siguiente enlace se puede ver su descripción: https://nlp.stanford.edu/software/spanish-faq.shtml\n","\n","\n","* Se debe descargar el software especifico proporcionado por la universidad de Standford a través del siguiente enlace: https://nlp.stanford.edu/software/tagger.shtml\n","\n","* Una vez descargada la librería tenemos que:\n","    1. Descomprimir el fichero\n","    2. Obtener el jar: stanford-postagger-4.2.0.jar\n","    3. Obtener el tagger spanish-ud.tagger que se encuentra dentro de la carpeta models\n","    4. Subir estos archivos a tu espacio de trabajo en Colab.\n","\n","\n","* También puedes encontrar estos 2 archivos en la carpeta 'libs' del archivo comprimido del presente laboratorio en el Classroom.\n","\n","\n","* Ejemplo:"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"tNSwVMlvZHKL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756705227300,"user_tz":300,"elapsed":1904,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"fde46652-ef4a-4578-f35e-5970f1709948"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('El', 'DET'), ('cine', 'NOUN'), ('es', 'AUX'), ('una', 'DET'), ('forma', 'NOUN'), ('de', 'ADP'), ('arte', 'NOUN'), ('que', 'PRON'), ('nos', 'PRON'), ('permite', 'VERB'), ('experimentar', 'VERB'), ('emociones', 'NOUN'), ('y', 'CCONJ'), ('explorar', 'VERB'), ('nuevas', 'ADJ'), ('realidades', 'NOUN'), ('.', 'PUNCT')]\n"]}],"source":["# Importamos la función 'find_jars_within_path' del módulo 'nltk.internals'.\n","# Esta función es usada internamente por NLTK para encontrar archivos JAR.\n","from nltk.internals import find_jars_within_path\n","\n","# Importamos la clase 'StanfordPOSTagger' del módulo 'nltk.tag'\n","from nltk.tag import StanfordPOSTagger\n","\n","# Definimos la ubicación del archivo JAR que contiene el etiquetador POS Tagging de Stanford.\n","jar = \"stanford-postagger-4.2.0.jar\"\n","\n","# Definimos la ubicación del archivo de modelo que el etiquetador utilizará.\n","tagger_file = \"spanish-ud.tagger\"\n","\n","# Creamos una nueva instancia de 'StanfordPOSTagger' con la ubicación del archivo de modelo y el archivo JAR.\n","tagger = StanfordPOSTagger(tagger_file, jar)\n","\n","# Definimos una cadena que queremos etiquetar.\n","doc = \"El cine es una forma de arte que nos permite experimentar emociones y explorar nuevas realidades.\"\n","\n","# Utilizamos la función 'word_tokenize' de NLTK para dividir la cadena en palabras individuales.\n","words = nltk.word_tokenize(doc)\n","\n","# Utilizamos el etiquetador POS de Stanford que creamos para etiquetar las palabras de la cadena.\n","tags = tagger.tag(words)\n","\n","# Imprimimos las palabras etiquetadas.\n","print(tags)\n"]},{"cell_type":"markdown","metadata":{"id":"wKasFf9IZHKM"},"source":["* **Nota**: Algunas de las etiquetas son diferentes a las de NLTK.\n","* Mas informacion: [PoS Tagging - Spanish FAQ for Stanford CoreNLP](https://nlp.stanford.edu/software/spanish-faq.shtml)"]},{"cell_type":"markdown","metadata":{"id":"6XY51makZHKM"},"source":["### **n-gramas**\n","\n","* Modelo de representación que selecciona secuencias contiguas de N elementos de la selección de texto."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Xp0FdfO2ZHKN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756704834776,"user_tz":300,"elapsed":43,"user":{"displayName":"CIRO GABRIEL CALLAPINA CASTILLA","userId":"13549179744361839230"}},"outputId":"98868587-f4f6-4661-ddca-a9479e4a30da"},"outputs":[{"output_type":"stream","name":"stdout","text":["('Los', 'libros', 'constituyen')\n","('libros', 'constituyen', 'una')\n","('constituyen', 'una', 'fuente')\n","('una', 'fuente', 'de')\n","('fuente', 'de', 'conocimiento')\n","('de', 'conocimiento', 'inagotable')\n"]}],"source":["# Importamos la función 'ngrams' del módulo nltk.\n","from nltk import ngrams\n","\n","# Definimos una cadena de texto.\n","doc = \"Los libros constituyen una fuente de conocimiento inagotable\"\n","\n","# Utilizamos la función 'word_tokenize' para dividir la cadena en palabras individuales.\n","words = nltk.word_tokenize(doc)\n","\n","# Definimos el número de elementos que queremos en cada n-grama.\n","num_elementos = 3\n","\n","# Utilizamos la función 'ngrams' para generar n-gramas de la lista de palabras.\n","n_grams = list(ngrams(words, num_elementos))\n","\n","# Iteramos a través de los n-gramas generados e imprimimos cada uno.\n","for gram in n_grams:\n","  print(gram)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}