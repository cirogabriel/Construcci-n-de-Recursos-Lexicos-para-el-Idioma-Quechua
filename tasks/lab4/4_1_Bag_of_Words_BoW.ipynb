{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROCESAMIENTO DE LENGUAJE NATURAL**\n",
        "\n",
        "#**Bag of Words (BoW) - Bolsa de palabras**\n",
        "\n",
        "El modelo de Bag of Words (BoW) es una técnica utilizada para representar datos de texto. En este modelo, un documento se representa como un conjunto de palabras sin tener en cuenta la estructura gramatical o el orden en que aparecen.\n",
        "\n",
        "La idea básica detrás del BoW es crear un vocabulario de todas las palabras únicas en un conjunto de documentos y luego contar cuántas veces aparece cada palabra en cada documento. Esto resulta en una representación vectorial donde cada dimensión del vector corresponde a una palabra en el vocabulario y el valor en esa dimensión indica la frecuencia de esa palabra en el documento."
      ],
      "metadata": {
        "id": "InEhVGf2XAEl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "4aXoN5Zh6DMk"
      },
      "source": [
        "\n",
        "A continuación se muestra con código python como obtener una bolsa de palabras a partir del siguiente \"corpus\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {},
        "id": "8zdau6Dt6DMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d7c0f5-26f0-4a93-ad61-9112ca369951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'política': 6, 'ser': 3, 'tema': 1, 'importante': 2, 'sociedad': 2, 'gobierno': 4, 'elecciones': 3, 'país': 4, 'evento': 1, 'político': 3, 'partidos': 1, 'políticos': 2, 'competir': 1, 'democracia': 1, 'presidente': 1, 'liderar': 1, 'leyes': 1, 'promulgar': 1, 'legal': 1, 'económica': 1, 'afectar': 1, 'ciudadanos': 2, 'campañas': 1, 'políticas': 1, 'influir': 1, 'participar': 1, 'proceso': 1, 'opinión': 1, 'pública': 1, 'debates': 1, 'discutir': 1, 'temas': 1}\n"
          ]
        }
      ],
      "source": [
        "# crear corpus de documentos\n",
        "documents = [\n",
        "    \"política ser tema importante sociedad política gobierno\",\n",
        "    \"elecciones gobierno país ser evento político\",\n",
        "    \"partidos políticos competir elecciones política democracia\",\n",
        "    \"presidente país liderar gobierno política\",\n",
        "    \"leyes gobierno promulgar político legal\",\n",
        "    \"política económica país afectar ciudadanos\",\n",
        "    \"campañas políticas influir elecciones país\",\n",
        "    \"ciudadanos participar proceso político\",\n",
        "    \"opinión pública ser importante política\",\n",
        "    \"debates políticos discutir temas sociedad\"\n",
        "]\n",
        "\n",
        "\n",
        "bow = dict()\n",
        "\n",
        "for doc in documents:\n",
        "    doc = doc.split(' ')\n",
        "    for word in doc:\n",
        "        if word in bow:\n",
        "            bow[word] += 1\n",
        "        else:\n",
        "            bow[word] = 1\n",
        "\n",
        "print(bow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "-d5I6Gza6DMt"
      },
      "source": [
        "* La construcción de las bolsas de palabras no solo se centran en la frecuencia si no que existen otras maneras de asignar un \"peso\" o \"importancia\" dentro del documento o del corpus a las palabras.\n",
        "\n",
        "\n",
        "* Aunque existen más formas de construir bolsas de palabras, las más utilizadas son las siguiente:\n",
        "\n",
        "    1. Vectores de Frecuencias\n",
        "    2. One-Hot-Encode\n",
        "    3. Term Frequency - Inverse Document Frequency (TF-IDF)\n",
        "    \n",
        "    \n",
        "* Veamos a continuación como implementar estas bolsas de palabras con las siguientes librerías:\n",
        "\n",
        "    * ***scikit***\n",
        "    * ***NLTK***\n",
        "    * ***Gensim***\n",
        "    \n",
        "    \n",
        "<hr>\n",
        "\n",
        "\n",
        "### **1. Vectores de Frecuencias**\n",
        "\n",
        "* Los ***vectores de frecuencias*** es el método más trivial de construir las ***Bolsas de Palabras***.\n",
        "\n",
        "\n",
        "* Simplemente consiste en contar cuantas veces aparece una palabra en el documento del corpus.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **- scikit**\n",
        "\n",
        "* Esta librería devuelve una matriz en la que las **filas representan a cada documento del corpus** y las **columnas el número de apariciones de las palabras**.\n",
        "\n",
        "\n",
        "* Para saber que palabra corresponde a cada columan de la matriz, scikit nos devuelve una lista en la que coinciden los indice de cada una de las palabras de la lista con la matriz.\n",
        "\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
      ],
      "metadata": {
        "id": "99-i5gOKW-s5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {},
        "id": "wDOaLX0r6DMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb81cc5-c4a2-46d6-9bc0-ab744f51e6f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de términos del vocabulario\n",
            "['afectar' 'campañas' 'ciudadanos' 'competir' 'debates' 'democracia'\n",
            " 'discutir' 'económica' 'elecciones' 'evento' 'gobierno' 'importante'\n",
            " 'influir' 'legal' 'leyes' 'liderar' 'opinión' 'participar' 'partidos'\n",
            " 'país' 'política' 'políticas' 'político' 'políticos' 'presidente'\n",
            " 'proceso' 'promulgar' 'pública' 'ser' 'sociedad' 'tema' 'temas']\n",
            "\n",
            " BoW binario\n",
            "[[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 1 1 0]\n",
            " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
            " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# Importar la clase CountVectorizer para convertir el texto en vectores de características.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convertir los documentos en una matriz de vectores de características utilizando el método fit_transform.\n",
        "vectorizer = CountVectorizer()\n",
        "vectors = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Imprimir los nombres de las características\n",
        "print ('Lista de términos del vocabulario')\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "# Imprimir la matriz de vectores de características.\n",
        "print ('\\n BoW binario')\n",
        "print(vectors.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "wTi7ipfx6DMu"
      },
      "source": [
        "#### **- NLTK**\n",
        "\n",
        "NLTK trabajar con diccionarios (un diccionario por documento) cuyas claves son las palabras y los valores son el número de apariciones de esa palabra en el documento."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrU_LXr2KY3l",
        "outputId": "a3e464e1-d2f1-4905-ea12-e0987da0e3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {},
        "id": "1LceVZL16DMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511bbea0-be6d-4c48-86fe-8f4a349ce1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {'política': 2, 'ser': 1, 'tema': 1, 'importante': 1, 'sociedad': 1, 'gobierno': 1})\n",
            "defaultdict(<class 'int'>, {'elecciones': 1, 'gobierno': 1, 'país': 1, 'ser': 1, 'evento': 1, 'político': 1})\n",
            "defaultdict(<class 'int'>, {'partidos': 1, 'políticos': 1, 'competir': 1, 'elecciones': 1, 'política': 1, 'democracia': 1})\n",
            "defaultdict(<class 'int'>, {'presidente': 1, 'país': 1, 'liderar': 1, 'gobierno': 1, 'política': 1})\n",
            "defaultdict(<class 'int'>, {'leyes': 1, 'gobierno': 1, 'promulgar': 1, 'político': 1, 'legal': 1})\n",
            "defaultdict(<class 'int'>, {'política': 1, 'económica': 1, 'país': 1, 'afectar': 1, 'ciudadanos': 1})\n",
            "defaultdict(<class 'int'>, {'campañas': 1, 'políticas': 1, 'influir': 1, 'elecciones': 1, 'país': 1})\n",
            "defaultdict(<class 'int'>, {'ciudadanos': 1, 'participar': 1, 'proceso': 1, 'político': 1})\n",
            "defaultdict(<class 'int'>, {'opinión': 1, 'pública': 1, 'ser': 1, 'importante': 1, 'política': 1})\n",
            "defaultdict(<class 'int'>, {'debates': 1, 'políticos': 1, 'discutir': 1, 'temas': 1, 'sociedad': 1})\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necesarias para tokenización y creación del BoW\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Función de tokenización usando NLTK\n",
        "def tokenize(text):\n",
        "    for token in nltk.word_tokenize(text):\n",
        "        yield token\n",
        "\n",
        "\n",
        "# Función para vectorizar un texto en un diccionario de frecuencias\n",
        "def vectorize(corpus):\n",
        "    features = defaultdict(int)\n",
        "    for token in tokenize(corpus):\n",
        "        features[token] += 1\n",
        "    return features\n",
        "\n",
        "\n",
        "# Generar vectores BoW para cada documento del corpus\n",
        "vectors = map(vectorize, documents)\n",
        "\n",
        "# Mostrar los resultados\n",
        "for v in vectors:\n",
        "    print(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "id": "EUFLkKvT6DMw"
      },
      "source": [
        "#### **- Gensim**\n",
        "\n",
        "* ***Gensim trabaja con \"Diccionarios\"*** (implementados como gensim.corpora.Dictionary) los cuales son una estructura de datos que mapea cada palabra única en el corpus a un identificador único (id), es decir, no conserva el orden de las palabras, sino que se encarga de la tarea de asignar un identificador a cada palabra única.\n",
        "\n",
        "* Una vez creado el \"Diccionario\", se puede utilizar para convertir documentos en representaciones de \"Bolsa de Palabras\", utilizando la función \"***doc2bow***\". En una representación de Bolsa de Palabras, cada documento se representa como una lista de tuplas. Cada tupla consta de un identificador de palabra (obtenido del \"Diccionario\") y la frecuencia de esa palabra en el documento.\n",
        "\n",
        "* Como resultado de este proceso, se obtiene una lista de listas por cada documento, donde cada lista interna contiene tuplas. Cada tupla representa una palabra en el documento identificada por su 'id' y la frecuencia de esa palabra en el documento\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/corpora/dictionary.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "xKYz7RGiIUzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d14c0a0-20f7-429c-ae3f-316ebc34a9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7ViTWBN6DMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fdbc05-9c68-42cb-de5a-56e56eac0a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario de palabras -> palabra: identificador\n",
            "\n",
            "{'gobierno': 0, 'importante': 1, 'política': 2, 'ser': 3, 'sociedad': 4, 'tema': 5, 'elecciones': 6, 'evento': 7, 'país': 8, 'político': 9, 'competir': 10, 'democracia': 11, 'partidos': 12, 'políticos': 13, 'liderar': 14, 'presidente': 15, 'legal': 16, 'leyes': 17, 'promulgar': 18, 'afectar': 19, 'ciudadanos': 20, 'económica': 21, 'campañas': 22, 'influir': 23, 'políticas': 24, 'participar': 25, 'proceso': 26, 'opinión': 27, 'pública': 28, 'debates': 29, 'discutir': 30, 'temas': 31}\n",
            "\n",
            "Apariciones de las palabras en los documentos:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1)],\n",
              " [(0, 1), (3, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
              " [(2, 1), (6, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
              " [(0, 1), (2, 1), (8, 1), (14, 1), (15, 1)],\n",
              " [(0, 1), (9, 1), (16, 1), (17, 1), (18, 1)],\n",
              " [(2, 1), (8, 1), (19, 1), (20, 1), (21, 1)],\n",
              " [(6, 1), (8, 1), (22, 1), (23, 1), (24, 1)],\n",
              " [(9, 1), (20, 1), (25, 1), (26, 1)],\n",
              " [(1, 1), (2, 1), (3, 1), (27, 1), (28, 1)],\n",
              " [(4, 1), (13, 1), (29, 1), (30, 1), (31, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "import gensim\n",
        "\n",
        "# Tokenizar cada documento en el corpus.\n",
        "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
        "\n",
        "# Crear un diccionario de palabras a partir de los tokens.\n",
        "dictionary = gensim.corpora.Dictionary(tokenize)\n",
        "\n",
        "# Convertir cada documento tokenizado en un BoW usando el diccionario.\n",
        "vectors = [dictionary.doc2bow(token) for token in tokenize]\n",
        "\n",
        "# Imprimir los resultados.\n",
        "print('Diccionario de palabras -> palabra: identificador\\n')\n",
        "print(dictionary.token2id)\n",
        "print('\\nApariciones de las palabras en los documentos:')\n",
        "vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lDzaov4B6DMx"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **2. BoW binario**\n",
        "\n",
        "* Este método de construcción de la ***Bolsa de Palabras*** consiste en indicar con un flag ([0,1], [True, False], etc.) si una palabra aparece o no en el documento."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **- scikit**\n",
        "\n",
        "* Las estructuras de datos de salida de ***scikit*** son iguales de en el caso de la construcción del vector de frecuencias salvo que en el contenido de la matriz solo hay ceros y unos.\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer"
      ],
      "metadata": {
        "id": "UEFx3lBJhRor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "mqXNX3o-6DMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f97a07c-bf70-4d16-9e8a-c5bbc663ce3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Términos del vocuabulario: \n",
            "['afectar' 'campañas' 'ciudadanos' 'competir' 'debates' 'democracia'\n",
            " 'discutir' 'económica' 'elecciones' 'evento' 'gobierno' 'importante'\n",
            " 'influir' 'legal' 'leyes' 'liderar' 'opinión' 'participar' 'partidos'\n",
            " 'país' 'política' 'políticas' 'político' 'políticos' 'presidente'\n",
            " 'proceso' 'promulgar' 'pública' 'ser' 'sociedad' 'tema' 'temas']\n",
            "\n",
            " BoW binario\n",
            "[[0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0]\n",
            " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
            " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# Importar CountVectorizer para convertir texto en vectores de características\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Importar la clase Binarizer para realizar BoW binario.\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "# convertir el corpus en una matriz de frecuencia de términos\n",
        "vectorizer = CountVectorizer()\n",
        "corpus = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Crear una instancia de Binarizer para realizar BoW binario\n",
        "onehot = Binarizer()\n",
        "\n",
        "# Aplicar BoW binario a la matriz de términos y documentos.\n",
        "corpus = onehot.fit_transform(corpus.toarray())\n",
        "\n",
        "# Imprimir los nombres de las características o términos\n",
        "print ('Términos del vocuabulario: ')\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n",
        "# Imprimir la matriz de BoW binario.\n",
        "print('\\n BoW binario')\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "Ye_Tx-lk6DMz"
      },
      "source": [
        "#### **- NLTK**\n",
        "\n",
        "* La estructura de datos de salida de ***NLTK*** es la misma que en el caso de la construcción del vector de frecuencias salvo que los valores del diccionario son ***booleanos*** en vez de numéricos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "SqDjiaKS6DMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe32170f-2492-471a-9eb1-f63be3f5bb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW binario\n",
            "{'política': True, 'ser': True, 'tema': True, 'importante': True, 'sociedad': True, 'gobierno': True}\n",
            "{'elecciones': True, 'gobierno': True, 'país': True, 'ser': True, 'evento': True, 'político': True}\n",
            "{'partidos': True, 'políticos': True, 'competir': True, 'elecciones': True, 'política': True, 'democracia': True}\n",
            "{'presidente': True, 'país': True, 'liderar': True, 'gobierno': True, 'política': True}\n",
            "{'leyes': True, 'gobierno': True, 'promulgar': True, 'político': True, 'legal': True}\n",
            "{'política': True, 'económica': True, 'país': True, 'afectar': True, 'ciudadanos': True}\n",
            "{'campañas': True, 'políticas': True, 'influir': True, 'elecciones': True, 'país': True}\n",
            "{'ciudadanos': True, 'participar': True, 'proceso': True, 'político': True}\n",
            "{'opinión': True, 'pública': True, 'ser': True, 'importante': True, 'política': True}\n",
            "{'debates': True, 'políticos': True, 'discutir': True, 'temas': True, 'sociedad': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Función de tokenización usando NLTK\n",
        "def tokenize(text):\n",
        "    for token in nltk.word_tokenize(text):\n",
        "        yield token\n",
        "\n",
        "\n",
        "# Función para vectorizar un texto en un BoW binario\n",
        "def vectorize(corpus):\n",
        "    return {token: True for token in tokenize(corpus)}\n",
        "\n",
        "\n",
        "# Generar vectores BoW binarios para cada documento del corpus\n",
        "vectors = map(vectorize, documents)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print('BoW binario')\n",
        "for v in vectors:\n",
        "    print(v)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "48Sqkgfc6DM0"
      },
      "source": [
        "#### **- Gensim**\n",
        "\n",
        "* En ***Gensim***, la estructura de los datos de salida es similar a la de una \"Bolsa de Palabras\". Sin embargo, en lugar de almacenar las frecuencias de las palabras en cada documento, cada palabra en un documento se representa con un valor de '1'.\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/corpora/dictionary.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {},
        "id": "bgIxvTeR6DM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed8f726-c18f-4a5b-8b23-84ea4ddc9455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario de palabras -> palabra: id\n",
            "\n",
            "{'gobierno': 0, 'importante': 1, 'política': 2, 'ser': 3, 'sociedad': 4, 'tema': 5, 'elecciones': 6, 'evento': 7, 'país': 8, 'político': 9, 'competir': 10, 'democracia': 11, 'partidos': 12, 'políticos': 13, 'liderar': 14, 'presidente': 15, 'legal': 16, 'leyes': 17, 'promulgar': 18, 'afectar': 19, 'ciudadanos': 20, 'económica': 21, 'campañas': 22, 'influir': 23, 'políticas': 24, 'participar': 25, 'proceso': 26, 'opinión': 27, 'pública': 28, 'debates': 29, 'discutir': 30, 'temas': 31}\n",
            "\n",
            "Apariciones de las palabras en los documentos (id, 1):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
              " [(0, 1), (3, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
              " [(2, 1), (6, 1), (10, 1), (11, 1), (12, 1), (13, 1)],\n",
              " [(0, 1), (2, 1), (8, 1), (14, 1), (15, 1)],\n",
              " [(0, 1), (9, 1), (16, 1), (17, 1), (18, 1)],\n",
              " [(2, 1), (8, 1), (19, 1), (20, 1), (21, 1)],\n",
              " [(6, 1), (8, 1), (22, 1), (23, 1), (24, 1)],\n",
              " [(9, 1), (20, 1), (25, 1), (26, 1)],\n",
              " [(1, 1), (2, 1), (3, 1), (27, 1), (28, 1)],\n",
              " [(4, 1), (13, 1), (29, 1), (30, 1), (31, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "import gensim\n",
        "\n",
        "# Tokenizar cada documento en el corpus.\n",
        "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
        "\n",
        "# Crear un diccionario de palabras a partir de los tokens.\n",
        "dictionary = gensim.corpora.Dictionary(tokenize)\n",
        "\n",
        "# Convertir cada documento tokenizado en una representación de BoW binario usando el diccionario.\n",
        "vectors = [[(token[0], 1) for token in dictionary.doc2bow(doc)] for doc in tokenize]\n",
        "\n",
        "# Imprimir los resultados.\n",
        "print('Diccionario de palabras -> palabra: id\\n')\n",
        "print(dictionary.token2id)\n",
        "print('\\nApariciones de las palabras en los documentos (id, 1):')\n",
        "vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "RZ8dpv4y6DM1"
      },
      "source": [
        "<hr>\n",
        "\n",
        "### **3. Term Frequency-Inverse Document Frequency (TF-IDF)**\n",
        "\n",
        "* El TF-IDF (Frecuencia de Termino - Frecuencia Inversa de Documento) es una medida numérica que permite expresar como de relevante es una palabra para un documento en una colección de documentos (o corpus).\n",
        "\n",
        "* Construir la Bolsa de Palabras con TF-IDF en vez de con frecuencias evita dar \"importancia\" a texto muy largos y con mucha repetición de palabras, frente a textos cortos y con pocas repeticiones de palabras. En lugar de solo contar las frecuencias de las palabras, permite tener una representación más equilibrada y significativa de los documentos en un corpus\n",
        "\n",
        "* La media de ***TF-IDF*** tiene dos componentes que son:\n",
        "    \n",
        "    * ***TF*** (Term Frecuency): Es la frecuencia con la que aparece la palabra en un documento del corpus. Esta se define como:\n",
        "    \n",
        "    $$tf(t,d) = 1 + log(f_{t,d})$$\n",
        "    \n",
        "    Al aplicar el logaritmo a la frecuencia del término se logra atenuar el efecto de las diferencias extremas en las frecuencias de los términos y proporcionar una representación más equilibrada\n",
        "    * ***IDF*** (Inverse Document Frequency): La frecuencia inversa del documento nos indica lo común que es una palabra en el corpus.\n",
        "    \n",
        "    $$idf(t,D) = log(1 + \\frac{N}{n_t})$$\n",
        "    \n",
        "\n",
        "* ***TF-IDF*** queda definido como:\n",
        "$$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Ejemplos:**\n",
        "\n",
        "* Veamos un ejemplo dado el siguiente corpus de 2 documentos con las siguientes palabras:\n",
        "\n",
        "```\n",
        "corpus = [\"messi messi messi ronaldo ronaldo balon\",\n",
        "          \"messi ronaldo futbol futbol futbol\"]\n",
        "```\n",
        "\n",
        "* ***Ejemplo 1***: Calculamos el ***tf-idf*** de la palabra \"**messi**\" para el documento 1:\n",
        "    \n",
        "    * ***TF***:\n",
        "        - t: número de veces que aparece la palabra \"messi\" en el documento 1 -> 3\n",
        "        - d: número de palabras que tiene el documento 1 -> 6\n",
        "        $$tf(t,d) = 1 + log(\\frac{3}{6}) =  0,69$$\n",
        "        \n",
        "    * ***IDF***:\n",
        "        - n<sub>t</sub>: número de documentos en los que aparece la palabra 'messi' -> 2\n",
        "        - D: número total de documentos en el corpus -> 2\n",
        "        $$idf(t,D) = log(1 + \\frac{2}{2}) = 0,3$$\n",
        "        \n",
        "    * ***TF-IDF***:\n",
        "    $$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D) = 0,69 * 0,3 = 0,21$$\n",
        "    \n",
        "    \n",
        "* ***Ejemplo 2***: Calculamos el ***tf-idf*** de la palabra \"**futbol**\" para el documento 2:\n",
        "    \n",
        "    * ***TF***:\n",
        "        - t: número de veces que aparece la palabra \"futbol\" en el documento 2 -> 3\n",
        "        - d: número de palabras que tiene el documento 2 -> 5\n",
        "        $$tf(t,d) = 1 + log(\\frac{3}{5}) =  0,78$$\n",
        "        \n",
        "    * ***IDF***:\n",
        "        - n<sub>t</sub>: número de documentos en los que aparece la palabra 'futbol' -> 1\n",
        "        - D: número total de documentos en el corpus -> 2\n",
        "        $$idf(t,D) = log(1 + \\frac{2}{1}) = 0,48$$\n",
        "        \n",
        "    * ***TF-IDF***:\n",
        "$$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D) = 0,78 * 0,48 = 0,37$$"
      ],
      "metadata": {
        "id": "M7vxZ10mq7yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementación:**\n",
        "\n",
        "\n",
        "* En el ejemplo mostrado anteriormente se ha realizado sobre el un TF-IDF teórico, calculando la frecuencia escalada logaritmicamente y sobre un corpus de \"juguete\" para entender el concepto.\n",
        "\n",
        "\n",
        "* Las implementaciones del ***TF-IDF*** de **scikit** y **Gensim** estan pensadas para corpus con un número relevante de documentos y de palabras, por tanto la implementación del ***TF-IDF*** acepta una serie de parámetros para no tener en cuenta Stop Words, palabras irrelevantes, etc. por lo que si se realiza una implementación del ***TF-IDF*** según la bibliografia no van a conincidir los resultados de esa implementación con los resultados de las librerías de **scikit** y **Gensim** a no ser que se modifiquen los parámetros de las funciones del ***TF-IDF***.\n"
      ],
      "metadata": {
        "id": "8TLeqPtOqpSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **- scikit**\n",
        "\n",
        "* Las estructuras de datos de salida de ***scikit*** son iguales de en el caso de la construcción del vector de frecuencias salvo que en el contenido de la matriz será de números decimales en vez de números enteros.\n",
        "\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
      ],
      "metadata": {
        "id": "F1qVDIHcrKpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "i0dmvm_V6DM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59ef3ad-c476-4ead-f58d-bbc73f531b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Términos del vocabulario: \n",
            "['afectar' 'campañas' 'ciudadanos' 'competir' 'debates' 'democracia'\n",
            " 'discutir' 'económica' 'elecciones' 'evento' 'gobierno' 'importante'\n",
            " 'influir' 'legal' 'leyes' 'liderar' 'opinión' 'participar' 'partidos'\n",
            " 'país' 'política' 'políticas' 'político' 'políticos' 'presidente'\n",
            " 'proceso' 'promulgar' 'pública' 'ser' 'sociedad' 'tema' 'temas']\n",
            "\n",
            " Vecores TF-IDF:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.30036745 0.38615948\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.5394939  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.33784392 0.38615948\n",
            "  0.45425645 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.3956317  0.53195646 0.35174493 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.35174493 0.         0.         0.3956317  0.\n",
            "  0.         0.         0.         0.         0.3956317  0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.46481913 0.         0.46481913\n",
            "  0.         0.         0.34569969 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.46481913 0.         0.27601929 0.         0.         0.39513872\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.36808452 0.\n",
            "  0.         0.         0.         0.5566674  0.         0.\n",
            "  0.         0.36808452 0.33056071 0.         0.         0.\n",
            "  0.5566674  0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.33101364 0.\n",
            "  0.         0.50060377 0.50060377 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.37231379 0.\n",
            "  0.         0.         0.50060377 0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.53357037 0.         0.45358356 0.         0.         0.\n",
            "  0.         0.53357037 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.3528121  0.31684521 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.50060377 0.         0.         0.         0.\n",
            "  0.         0.         0.37231379 0.         0.         0.\n",
            "  0.50060377 0.         0.         0.         0.         0.\n",
            "  0.         0.33101364 0.         0.50060377 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.46968604 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.55251242\n",
            "  0.         0.         0.         0.         0.41091978 0.\n",
            "  0.         0.55251242 0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.44627987\n",
            "  0.         0.         0.         0.         0.52497872 0.\n",
            "  0.         0.         0.31174331 0.         0.         0.\n",
            "  0.         0.         0.         0.52497872 0.39044215 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.47429543 0.\n",
            "  0.47429543 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.40319445\n",
            "  0.         0.         0.         0.         0.         0.40319445\n",
            "  0.         0.47429543]]\n"
          ]
        }
      ],
      "source": [
        "# Importar la clase TfidfVectorizer para calcular TF-IDF.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Crear una instancia de TfidfVectorizer para calcular TF-IDF.\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Convertir el corpus en una matriz de TF-IDF.\n",
        "corpus = tfidf.fit_transform(documents)\n",
        "\n",
        "# Imprimir los nombres de las características\n",
        "print ('Términos del vocabulario: ')\n",
        "print(tfidf.get_feature_names_out())\n",
        "\n",
        "# Imprimir la matriz de TF-IDF.\n",
        "print ('\\n Vecores TF-IDF:')\n",
        "print(corpus.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        },
        "id": "1t3BfG066DM2"
      },
      "source": [
        "#### **- Gensim**\n",
        "\n",
        "* La estructura de datos de salida de ***Gensim*** es la misma que en el caso de la construcción de la Bolsa de Palabras de frecuencias salvo que los valores de las palabras en los documentos tendrán números decimales en vez de números enteros.\n",
        "\n",
        "\n",
        "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/models/tfidfmodel.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        },
        "id": "xqKJmlo06DM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a3da34-fe5e-4459-a715-4aa36cd44bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diccionario de palabras -> palabra: id\n",
            "\n",
            "{'gobierno': 0, 'importante': 1, 'política': 2, 'ser': 3, 'sociedad': 4, 'tema': 5, 'elecciones': 6, 'evento': 7, 'país': 8, 'político': 9, 'competir': 10, 'democracia': 11, 'partidos': 12, 'políticos': 13, 'liderar': 14, 'presidente': 15, 'legal': 16, 'leyes': 17, 'promulgar': 18, 'afectar': 19, 'ciudadanos': 20, 'económica': 21, 'campañas': 22, 'influir': 23, 'políticas': 24, 'participar': 25, 'proceso': 26, 'opinión': 27, 'pública': 28, 'debates': 29, 'discutir': 30, 'temas': 31}\n",
            "\n",
            "Apariciones de las palabras en los documentos (id, tfidf):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 0.23904061476607658),\n",
              "  (1, 0.4198678592210365),\n",
              "  (2, 0.3616544889099199),\n",
              "  (3, 0.31409070210614737),\n",
              "  (4, 0.4198678592210365),\n",
              "  (5, 0.6006951036759965)],\n",
              " [(0, 0.272222219104851),\n",
              "  (3, 0.35769012730831634),\n",
              "  (6, 0.35769012730831634),\n",
              "  (7, 0.6840785373988446),\n",
              "  (8, 0.272222219104851),\n",
              "  (9, 0.35769012730831634)],\n",
              " [(2, 0.15336770617138346),\n",
              "  (6, 0.2663944288758852),\n",
              "  (10, 0.5094764919791486),\n",
              "  (11, 0.5094764919791486),\n",
              "  (12, 0.5094764919791486),\n",
              "  (13, 0.3561087858077651)],\n",
              " [(0, 0.25647772361020643),\n",
              "  (2, 0.19401790808603714),\n",
              "  (8, 0.25647772361020643),\n",
              "  (14, 0.6445135397822808),\n",
              "  (15, 0.6445135397822808)],\n",
              " [(0, 0.21481235202011797),\n",
              "  (9, 0.28225564318054464),\n",
              "  (16, 0.53981089445358),\n",
              "  (17, 0.53981089445358),\n",
              "  (18, 0.53981089445358)],\n",
              " [(2, 0.18194075042224608),\n",
              "  (8, 0.24051258958805682),\n",
              "  (19, 0.604394090432549),\n",
              "  (20, 0.4224533400103029),\n",
              "  (21, 0.604394090432549)],\n",
              " [(6, 0.28225564318054464),\n",
              "  (8, 0.21481235202011797),\n",
              "  (22, 0.53981089445358),\n",
              "  (23, 0.53981089445358),\n",
              "  (24, 0.53981089445358)],\n",
              " [(9, 0.314624253295364),\n",
              "  (20, 0.4205810958565021),\n",
              "  (25, 0.6017155146107164),\n",
              "  (26, 0.6017155146107164)],\n",
              " [(1, 0.41384679758352894),\n",
              "  (2, 0.17823411435297046),\n",
              "  (3, 0.3095865243377949),\n",
              "  (27, 0.5920809119364995),\n",
              "  (28, 0.5920809119364995)],\n",
              " [(4, 0.3504889200129061),\n",
              "  (13, 0.3504889200129061),\n",
              "  (29, 0.5014362817269253),\n",
              "  (30, 0.5014362817269253),\n",
              "  (31, 0.5014362817269253)]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import nltk\n",
        "import gensim\n",
        "\n",
        "# Tokenizar cada documento en el corpus.\n",
        "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
        "\n",
        "# Crear un diccionario de palabras a partir de los tokens.\n",
        "dictionary = gensim.corpora.Dictionary(tokenize)\n",
        "\n",
        "# Crear un modelo TF-IDF a partir del diccionario.\n",
        "tfidf = gensim.models.TfidfModel(dictionary=dictionary, normalize=True)\n",
        "\n",
        "# Calcular los vectores TF-IDF para cada documento.\n",
        "vectors = [tfidf[dictionary.doc2bow(doc)] for doc in tokenize]\n",
        "\n",
        "# Imprimir los resultados.\n",
        "print('Diccionario de palabras -> palabra: id\\n')\n",
        "print(dictionary.token2id)\n",
        "print('\\nApariciones de las palabras en los documentos (id, tfidf):')\n",
        "vectors"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}